<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <script type="text/javascript" src="js/hidebib.js"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-89140762-1');
  </script>

  <title>Yi Xu</title>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">

  <meta name="author" content="Yi Xu">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" type="text/css" href="css/style.css">
  <link rel="icon" type="image/png" href="images/fudan.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:70%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yi Xu</name>
              </p>
              <p>I am a 5th-year PhD student in Computer Science at <a href="https://www.fudan.edu.cn/">Fudan University</a>, advised by <a href="http://admis.fudan.edu.cn/">Prof. Shuigeng Zhou</a>.
                I received my my bachelor's degree from Shanghai University.
              </p>
              <p>
                I work in the areas of video understanding and weakly/semi-supervised learning. In particular, I am interested in combining spatial
                and temporal information for learning spatiotemporal structure in videos and related weakly/semi-supervised tasks.
              </p>
              <p>
                I am working as a research intern in Tencent. I have worked as a research intern in DAMO Academy Alibaba (8 months), research intern in Bilibili AI group (3 years) and summer intern in Microsoft Bing Ads group (4 months).
                I received the 2019 Intel Fellowship and selected into the 2021 Tencent Rhino-Bird Elite Training Program.
              </p>
              <p style="text-align:center">
                <a href="mailto:yxu17@fudan.edu.cn">Email</a> &nbsp/&nbsp
                <a href="data/Yi_s_Resume.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=JfwCR6YAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/xyiyy">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/YiXu.jpg"><img style="width:100%;max-width:100%;border-radius:50%" alt="profile photo" src="images/YiXu.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <hr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                    <heading>Recent News</heading>
                </td>
            </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <ul>
              <li>Our paper on <a href="">Weakly Supervised Learning for Text Classification</a> is accepted by <b>EMNLP 2021</b>.</li>
              <li>Our paper on <a href="https://arxiv.org/pdf/2108.02110.pdf">Video Compression Artifact Reduction</a> is accepted by <b>MM 2021</b>.</li>
              <li>Our paper on <a href="https://arxiv.org/pdf/2105.14962.pdf">Video Compression Artifact Reduction</a> is accepted by <b>CVPR Workshp NTIRE 2021</b></li>
              <li>Our preprint on <a href="https://arxiv.org/pdf/2104.14802.pdf">Dance Style Transfering</a> is released. </li>
              <li>Our paper on <a href="https://www.aaai.org/AAAI21Papers/AAAI-1201.XuY.pdf">GIF Thumbnail Generation</a> is accepted by <b>AAAI 2021</b>.</li>
            </ul>
          </td>
        </tr>
        </tbody></table>
        <hr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td style="padding:20px;width:35%;vertical-align:middle">
                  <img src='images/zhao2021recursive.png' width="250"></div>
              </td>
              <td width="75%" valign="middle">
                  <p>
                  <a href="https://arxiv.org/pdf/2108.02110.pdf">
                      <papertitle>Recursive Fusion and Deformable Spatiotemporal Attention for Video Compression Artifact Reduction</papertitle>
                  </a>
                  <br>
                  <a>Minyi Zhao</a>,
                  <strong>Yi Xu (Co-author)</strong>,
                  <a>Shuigeng Zhou</a>,
                  <br>
                  <em>MM</em>, 2021
                  <br>
                  </p>
                  <div class="paper" id="zhao2021recursive">
                      <a href="https://arxiv.org/pdf/2108.02110.pdf">paper</a> /
                      <a href="data/zhao2021recursive.bib">bibtex</a> / 
                      <a href="https://github.com/zhaominyiz/RFDA-PyTorch">Code</a>
                  </div>
              </td>
          </tr> <!--MM 2021-->


          <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/xu2021boosting.png' width="250"></div>
            </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://arxiv.org/pdf/2105.14962.pdf">
                    <papertitle>Boosting the Performance of Video Compression Artifact Reduction with Reference Frame Proposals and Frequency Domain Information</papertitle>
                </a>
                <br>
                <strong>Yi Xu</strong>,
                <a>Minyi Zhao</a>,
                <a>Jing Liu</a>,
                <a>Xinjian Zhang</a>,
                <a>Longwen Gao</a>,
                <a>Shuigeng Zhou</a>,
                <a>Huyang Sun</a>
                <br>
                <em>CVPR Workshop</em>, 2021
                <br>
                NTIRE Challenge on Quality Enhancement of Compressed Video
                <br>
                <font color="red"><strong>Winner of Tracks 1 and 2, Runner-up of Track 3</strong></font>
                <br>
                </p>
                <div class="paper" id="xu2021boosting">
                    <a href="https://arxiv.org/pdf/2105.14962.pdf">paper</a> /
                    <a href="data/xu2021boosting.bib">bibtex</a> / 
                    <a href="https://github.com/RenYang-home/NTIRE21_VEnh#papers-codes-and-models-keep-updating">Challenge Page</a>
                </div>
            </td>
        </tr> <!--CVPRW 2021-->

          <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/zhang2021dance.png' width="250"></div>
            </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://arxiv.org/pdf/2104.14802.pdf">
                    <papertitle>Dance Generation with Style Embedding: Learning and Transferring Latent Representations of Dance Styles
                    </papertitle>
                </a>
                <br>
                <a>Xinjian Zhang</a>, 
                <strong>Yi Xu</strong>,
                <a>Su Yang</a>,
                <a>Longwen Gao</a>,
                <a>Huyang Sun</a>
                <br>
                <em>Arxiv</em>, PrePrint
                <br>
                </p>
                <div class="paper" id="zhang2021dance">
                    <a href="https://arxiv.org/pdf/2104.14802.pdf">paper</a> /
                    <a href="pro/DanceStyle.html">Demo</a> / 
                    <a href="data/zhang2021dance.bib">bibtex</a>
                </div>
            </td>
        </tr> <!--Dance Arxiv-->

        <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/yi2021gifthumbnail.png' width="250"></div>
            </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://www.aaai.org/AAAI21Papers/AAAI-1201.XuY.pdf">
                    <papertitle>GIF Thumbnails: Attract More Clicks to Your Videos</papertitle>
                </a>
                <br>
                <strong>Yi Xu</strong>,
                <a>Fan Bai</a>,
                <a>Yingxuan Shi</a>,
                <a>Qiuyu Chen</a>,
                <a>Longwen Gao</a>,
                <a>Kai Tian</a>,
                <a>Shuigeng Zhou</a>,
                <a>Huyang Sun</a>
                <br>
                <em>AAAI</em>, 2021
                <br>
                </p>
                <div class="paper" id="xu2021gif">
                    <a href="https://www.aaai.org/AAAI21Papers/AAAI-1201.XuY.pdf">paper</a> /
                    <a href="data/GITThumbnailSupp.pdf">Supp</a> /
                    <a href="https://virtual.2021.aaai.org/paper_AAAI-1201.html">Presentation</a> / 
                    <a href="https://github.com/xyiyy/GIF-Thumbnails">project page</a> /
                    <a>Demo</a> / 
                    <a href="data/xu2021gif.bib">bibtex</a>
                </div>
            </td>
        </tr> <!--AAAI 2021-->

          <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/ye2020optimal.png' width="250"></div>
            </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://link.springer.com/chapter/10.1007/978-3-030-59410-7_42">
                    <papertitle>Optimal Trade Execution Based on Deep Deterministic Policy Gradient</papertitle>
                </a>
                <br>
                <a>Zekun Ye</a>,
                <a>Weijie Deng</a>,
                <a>Shuigeng Zhou</a>,
                <strong>Yi Xu</strong>,
                <a>Jihong Guan</a>
                <br>
                <em>DASFAA</em>, 2020
                <br>
                </p>
                <div class="paper" id="ye2020optimal">
                    <a href="https://link.springer.com/chapter/10.1007/978-3-030-59410-7_42">paper</a> /
                    <a href="data/ye2020optimal.bib">bibtex</a>
                </div>
            </td>
        </tr> <!--DASFAA 2020-->

          <tr>
              <td style="padding:20px;width:35%;vertical-align:middle">
                  <img src='images/chen2020adaptive.png' width="250"></div>
              </td>
              <td width="75%" valign="middle">
                  <p>
                  <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_Adaptive_Fractional_Dilated_Convolution_Network_for_Image_Aesthetics_Assessment_CVPR_2020_paper.pdf">
                      <papertitle>Adaptive Fractional Dilated Convolution Network for Image Aesthetics Assessment</papertitle>
                  </a>
                  <br>
                  <a>Qiuyu Chen</a>,
                  <a>Wei Zhang</a>,
                  <a>Ning Zhou</a>,
                  <a>Peng Lei</a>,
                  <strong>Yi Xu</strong>,
                  <a>Yu Zheng</a>,
                  <a>Jianping Fan</a>
                  <br>
                  <em>CVPR</em>, 2020
                  <br>
                  </p>
                  <div class="paper" id="chen2020adaptive">
                      <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_Adaptive_Fractional_Dilated_Convolution_Network_for_Image_Aesthetics_Assessment_CVPR_2020_paper.pdf">paper</a> /
                      <a href="data/chen2020adaptive.bib">bibtex</a>
                  </div>
              </td>
          </tr> <!--CVPR 2020-->

          <tr>
              <td style="padding:20px;width:35%;vertical-align:middle">
                  <img src='images/tian2020nar.png' width="250"></div>
              </td>
              <td width="75%" valign="middle">
                  <p>
                  <a href="http://www.kaitian.io/pdfs/NaR_AAAI2020.pdf">
                      <papertitle>Network as Regularization for Training Deep Neural Networks: Framework, Model and Performance</papertitle>
                  </a>
                  <br>
                  <a href="http://www.kaitian.io/">Kai Tian</a>,
                  <strong>Yi Xu</strong>,
                  <a href="http://admis.fudan.edu.cn/">Shuigeng Zhou</a>,
                  <a>Jihong Guan</a>
                  <br>
                  <em>AAAI</em>, 2020 <font color="red"><strong>(Oral Presentation)</strong></font>
                  <br>
                  </p>
                  <div class="paper" id="tian2020network">
                      <a href="http://www.kaitian.io/pdfs/NaR_AAAI2020.pdf">paper</a> /
                      <a href="https://github.com/codeforNaR/NaR">project page</a> /
                      <a href="data/tian2020network.bib">bibtex</a>
                  </div>
              </td>
          </tr> <!--AAAI 2020-->

        
        <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/nlconv.png' width="250"></div>
            </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://arxiv.org/pdf/1910.12286">
                    <papertitle>Non-Local ConvLSTM for Video Compression Artifact Reduction</papertitle>
                </a>
                <br>
                <strong>Yi Xu</strong>,
                <a href='https://dblp.uni-trier.de/pers/hd/g/Gao:Longwen'>Longwen Gao</a>
                <a href="http://www.kaitian.io/">Kai Tian</a>,
                <a href="http://admis.fudan.edu.cn/">Shuigeng Zhou</a>,
                <a>Huyang Sun</a>
                <br>
                <em>ICCV</em>, 2019
                <br>
                </p>
                <div class="paper" id="xu2019non">
                    <a href="https://arxiv.org/pdf/1910.12286">paper</a> /
                    <a href="data/NL-ConvLSTM supp.pdf">Supp</a> /
                    <a href="https://github.com/xyiyy/NL-ConvLSTM">project page</a> /
                    <a href="https://xyiyy.github.io/pro/NLConvLSTM.html">Demo</a> /
                    <a href="data/xu2019non.bib">bibtex</a>
                </div>
            </td>
        </tr> <!--xu2019non-->


        <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/tian2019versatile.png' width="250"></div>
            </td>
            <td width="75%" valign="middle">
                <p>
                <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Tian_Versatile_Multiple_Choice_Learning_and_Its_Application_to_Vision_Computing_CVPR_2019_paper.pdf">
                    <papertitle>Versatile Multiple Choice Learning and Its Application to Vision Computing</papertitle>
                </a>
                <br>
                <a href="http://www.kaitian.io/">Kai Tian</a>,
                <strong>Yi Xu</strong>,
                <a href="http://admis.fudan.edu.cn/">Shuigeng Zhou</a>,
                <a>Jihong Guan</a>
                <br>
                <em>CVPR</em>, 2019
                <br>
                </p>
                <div class="paper" id="tian2019versatile">
                    <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Tian_Versatile_Multiple_Choice_Learning_and_Its_Application_to_Vision_Computing_CVPR_2019_paper.pdf">paper</a> /
                    <a href="data/tian2019versatile.bib">bibtex</a>
                </div>
            </td>
        </tr> <!--tian2019versatile-->


        <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/wu2019simple.png' width="250"></div>
            </td>
            <td width="75%" valign="middle">
                <p>
                <a href="data/PRICAI2019_paper_354.pdf">
                    <papertitle>Simple Is Better: A Global Semantic Consistency Based End-to-End Framework for Effective Zero-Shot Learning</papertitle>
                </a>
                <br>
                <a>Fan Wu</a>,
                <a href="http://admis.fudan.edu.cn/">Shuigeng Zhou</a>,
                <a>Kang Wang</a>,
                <strong>Yi Xu</strong>,
                <a>Jihong Guan</a>,
                <a href="http://research.baidu.com/People/index-view?id=112">Jun Huan</a>
                <br>
                <em>PRICAI</em>, 2019 <font color="red"><strong>(Oral Presentation)</strong></font>
                <br>
                </p>
                <div class="paper" id="wu2019simple">
                    <a href="data/PRICAI2019_paper_354.pdf">paper</a> /
                    <a href="data/wu2019simple.bib">bibtex</a>
                </div>
            </td>
        </tr> <!--wu2019simple-->

        <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/xu2018effective.png' width="250"></div>
            </td>
            <td width="75%" valign="middle">
                <p>
                <a href="data/xu2018effective.pdf">
                    <papertitle>Effective community division based on improved spectral clustering</papertitle>
                </a>
                <br>
                <strong>Yi Xu</strong>,
                <a href="https://scholar.google.com/citations?user=uut35tEAAAAJ&hl=en">Zhi Zhuang</a>,
                <a href="http://my.shu.edu.cn/cn/wmli">Weimin Li</a>
                <a href="https://researchers.shiga-u.ac.jp/html/100002605_en.html">Xiaokang Zhou</a>
                <br>
                <em>NeuroComputing</em>, 2018
                <br>
                </p>
                <div class="paper" id="xu2018effective">
                    <a href="data/xu2018effective.pdf">paper</a> /
                    <a href="data/xu2018effective.bib">bibtex</a>
                </div>
            </td>
        </tr> <!--xu2018effective-->

        </tbody></table>

        <hr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <!--td width=50% align="center">
              <a href="https://clustrmaps.com/site/1b2nv"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=_s2_OduoO888ugvX-pYCsciaAlSir2c84N9WH4N3AmQ&cl=ffffff" /></a>
            </td -->
            <td style="padding:0px">
              <br>
              <p style="text-align:right;">Stolen from <a href="https://jonbarron.info/">Jon Barron</a></p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>

<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>

<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-89140762-1', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics -->

</body>

</html>
